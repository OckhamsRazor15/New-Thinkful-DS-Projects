{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv = pd.read_csv(\"t_asv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Matthew', 'Mark', 'Luke', 'John', 'Paul', 'Unknown', 'James',\n",
       "       'Peter', 'Jude'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asv[\"Author\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_Matthew = asv[asv[\"Author\"] == \"Matthew\"]\n",
    "asv_Mark = asv[asv[\"Author\"] == \"Mark\"]\n",
    "asv_Luke = asv[asv[\"Author\"] == \"Luke\"]\n",
    "asv_John = asv[asv[\"Author\"] == \"John\"]\n",
    "asv_Paul = asv[asv[\"Author\"] == \"Paul\"]\n",
    "asv_Unknown = asv[asv[\"Author\"] == \"Unknown\"]\n",
    "asv_James = asv[asv[\"Author\"] == \"James\"]\n",
    "asv_Peter = asv[asv[\"Author\"] == \"Peter\"]\n",
    "asv_Jude = asv[asv[\"Author\"] == \"Jude\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_Matthew_doc = nlp(''.join(asv_Matthew[\"Text\"]))\n",
    "asv_Matthew_sents = [[sent, \"Matthew\"] for sent in asv_Matthew_doc.sents]\n",
    "\n",
    "asv_Mark_doc = nlp(''.join(asv_Mark[\"Text\"]))\n",
    "asv_Mark_sents = [[sent, \"Mark\"] for sent in asv_Mark_doc.sents]\n",
    "\n",
    "asv_Luke_doc = nlp(''.join(asv_Luke[\"Text\"]))\n",
    "asv_Luke_sents = [[sent, \"Luke\"] for sent in asv_Luke_doc.sents]\n",
    "\n",
    "asv_John_doc = nlp(''.join(asv_John[\"Text\"]))\n",
    "asv_John_sents = [[sent, \"John\"] for sent in asv_John_doc.sents]\n",
    "\n",
    "asv_Paul_doc = nlp(''.join(asv_Paul[\"Text\"]))\n",
    "asv_Paul_sents = [[sent, \"Paul\"] for sent in asv_Paul_doc.sents]\n",
    "\n",
    "asv_Unknown_doc = nlp(''.join(asv_Unknown[\"Text\"]))\n",
    "asv_Unknown_sents = [[sent, \"Unknown\"] for sent in asv_Unknown_doc.sents]\n",
    "\n",
    "asv_James_doc = nlp(''.join(asv_James[\"Text\"]))\n",
    "asv_James_sents = [[sent, \"James\"] for sent in asv_James_doc.sents]\n",
    "\n",
    "asv_Peter_doc = nlp(''.join(asv_Peter[\"Text\"]))\n",
    "asv_Peter_sents = [[sent, \"Peter\"] for sent in asv_Peter_doc.sents]\n",
    "\n",
    "asv_Jude_doc = nlp(''.join(asv_Jude[\"Text\"]))\n",
    "asv_Jude_sents = [[sent, \"Jude\"] for sent in asv_Jude_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Jude, a servant of Jesus Christ, and brother of James, to them that are called, beloved in God the Father, and kept for Jesus Christ:Mercy unto you and peace and love be multiplied.,\n",
       "  'Jude'],\n",
       " [Beloved, while I was giving all diligence to write unto you of our common salvation, I was constrained to write unto you exhorting you to contend earnestly for the faith which was once for all delivered unto the saints.,\n",
       "  'Jude'],\n",
       " [For there are certain men crept in privily, `even' they who were of old written of beforehand unto this condemnation, ungodly men, turning the grace of our God into lasciviousness, and denying our only Master and Lord, Jesus Christ.,\n",
       "  'Jude'],\n",
       " [Now I desire to put you in remembrance, though ye know all things once for all, that the Lord, having saved a people out of the land of Egypt, afterward destroyed them that believed not.,\n",
       "  'Jude'],\n",
       " [And angels that kept not their own principality, but left their proper habitation, he hath kept in everlasting bonds under darkness unto the judgment of the great day.,\n",
       "  'Jude'],\n",
       " [Even as Sodom and Gomorrah, and the cities about them, having in like manner with these given themselves over to fornication and gone after strange flesh, are set forth as an example, suffering the punishment of eternal fire.,\n",
       "  'Jude'],\n",
       " [Yet in like manner these also in their dreamings defile the flesh, and set at nought dominion, and rail at dignities.,\n",
       "  'Jude'],\n",
       " [But Michael the archangel, when contending with the devil he disputed about the body of Moses, durst not bring against him a railing judgment, but said, The Lord rebuke thee.,\n",
       "  'Jude'],\n",
       " [But these rail at whatsoever things they know not: and what they understand naturally, like the creatures without reason, in these things are they destroyed.,\n",
       "  'Jude'],\n",
       " [Woe unto them!, 'Jude'],\n",
       " [For they went in the way of Cain, and ran riotously in the error of Balaam for hire, and perished in the gainsaying of Korah.,\n",
       "  'Jude'],\n",
       " [These are they who are hidden rocks in your love-feasts when they feast with you, shepherds that without fear feed themselves; clouds without water, carried along by winds; autumn leaves without fruit, twice dead, plucked up by the roots;Wild waves of the sea, foaming out their own shame; wandering stars, for whom the blackness of darkness hath been reserved forever.,\n",
       "  'Jude'],\n",
       " [And to these also Enoch, the seventh from Adam, prophesied, saying, Behold, the Lord came with ten thousands of his holy ones,to execute judgment upon all, and to convict all the ungodly of all their works of ungodliness which they have ungodly wrought, and of all the hard things which ungodly sinners have spoken against him.,\n",
       "  'Jude'],\n",
       " [These are murmurers, complainers, walking after their lusts (and their mouth speaketh great swelling `words'), showing respect of persons for the sake of advantage.,\n",
       "  'Jude'],\n",
       " [But ye, beloved, remember ye the words which have been spoken before by the apostles of our Lord Jesus Christ;That they said to you, In the last time there shall be mockers, walking after their own ungodly lusts.,\n",
       "  'Jude'],\n",
       " [These are they who make separations, sensual, having not the Spirit.,\n",
       "  'Jude'],\n",
       " [But ye, beloved, building up yourselves on your most holy faith, praying in the Holy Spirit,keep yourselves in the love of God, looking for the mercy of our Lord Jesus Christ unto eternal life.,\n",
       "  'Jude'],\n",
       " [And on some have mercy, who are in doubt;and some save, snatching them out of the fire; and on some have mercy with fear; hating even the garment spotted by the flesh.,\n",
       "  'Jude'],\n",
       " [Now unto him that is able to guard you from stumbling, and to set you before the presence of his glory without blemish in exceeding joy,to the only God our Saviour, through Jesus Christ our Lord, `be' glory, majesty, dominion and power, before all time, and now, and for evermore.,\n",
       "  'Jude'],\n",
       " [Amen., 'Jude']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'spacy.tokens.doc.Doc' and 'spacy.tokens.doc.Doc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-256cd67e9e45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m df = pd.DataFrame(asv_Matthew_doc + asv_Mark_doc + asv_Luke_doc + asv_John_doc + asv_Paul_doc + asv_Unknown_doc\n\u001b[1;32m----> 2\u001b[1;33m                   + asv_James_doc + asv_Peter_doc + asv_Jude_doc)\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'spacy.tokens.doc.Doc' and 'spacy.tokens.doc.Doc'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(asv_Matthew_doc + asv_Mark_doc + asv_Luke_doc + asv_John_doc + asv_Paul_doc + asv_Unknown_doc\n",
    "                  + asv_James_doc + asv_Peter_doc + asv_Jude_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(asv_Matthew_sents + asv_Mark_sents + asv_Luke_sents + asv_John_sents + asv_Paul_sents + asv_Unknown_sents\n",
    "                  + asv_James_sents + asv_Peter_sents + asv_Jude_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(The, book, of, the, generation, of, Jesus, Ch...</td>\n",
       "      <td>Matthew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Abraham, begat, Isaac, ;, and, Isaac, begat, ...</td>\n",
       "      <td>Matthew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Jesse, begat)</td>\n",
       "      <td>Matthew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(David, the, king, .)</td>\n",
       "      <td>Matthew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(And, David, begat, Solomon, of, her, `, that,...</td>\n",
       "      <td>Matthew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (The, book, of, the, generation, of, Jesus, Ch...  Matthew\n",
       "1  (Abraham, begat, Isaac, ;, and, Isaac, begat, ...  Matthew\n",
       "2                                     (Jesse, begat)  Matthew\n",
       "3                              (David, the, king, .)  Matthew\n",
       "4  (And, David, begat, Solomon, of, her, `, that,...  Matthew"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = asv[\"Text\"]\n",
    "y = asv[\"Author\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Naive Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "#Logistic Regression\n",
    "text_clf_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Naive Bayes first\n",
    "text_clf_nb.fit(X_train, y_train)\n",
    "\n",
    "#run predictions\n",
    "prednb = text_clf_nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>James</th>\n",
       "      <th>John</th>\n",
       "      <th>Jude</th>\n",
       "      <th>Luke</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Matthew</th>\n",
       "      <th>Paul</th>\n",
       "      <th>Peter</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jude</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         James  John  Jude  Luke  Mark  Matthew  Paul  Peter  Unknown\n",
       "James        0     0     0     5     0        0    17      0        0\n",
       "John         0   156     0   130     0        1    59      0        0\n",
       "Jude         0     0     0     1     0        0     4      0        0\n",
       "Luke         0    14     0   450     0        3    73      0        0\n",
       "Mark         0     7     0   153     0        0    14      0        0\n",
       "Matthew      0    23     0   203     0        7    29      0        0\n",
       "Paul         0     6     0    55     0        0   465      0        0\n",
       "Peter        0     0     0     9     0        0    32      0        0\n",
       "Unknown      0     6     0    30     0        0    38      0        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(metrics.confusion_matrix(y_test,prednb), \n",
    "      index=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'], \n",
    "     columns=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(df3, cmap='Blues',annot=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       James       0.00      0.00      0.00        41\n",
      "        John       0.80      0.40      0.53       468\n",
      "        Jude       0.00      0.00      0.00         7\n",
      "        Luke       0.43      0.88      0.58       715\n",
      "        Mark       0.00      0.00      0.00       221\n",
      "     Matthew       0.86      0.03      0.06       359\n",
      "        Paul       0.64      0.88      0.74       672\n",
      "       Peter       0.00      0.00      0.00        42\n",
      "     Unknown       0.00      0.00      0.00       102\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      2627\n",
      "   macro avg       0.30      0.24      0.21      2627\n",
      "weighted avg       0.54      0.54      0.45      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,prednb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5393985534830605\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,prednb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.48529412, 0.50246305, 0.47761194, 0.49253731, 0.47738693,\n",
       "       0.53030303, 0.5255102 , 0.50510204, 0.5       , 0.51530612])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(text_clf_nb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's run linear SVC next\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "#predictions\n",
    "predsvc = text_clf_lsvc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>James</th>\n",
       "      <th>John</th>\n",
       "      <th>Jude</th>\n",
       "      <th>Luke</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Matthew</th>\n",
       "      <th>Paul</th>\n",
       "      <th>Peter</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jude</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>52</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         James  John  Jude  Luke  Mark  Matthew  Paul  Peter  Unknown\n",
       "James        3     2     0     7     3        2    23      1        0\n",
       "John         1   332     0    60    12       27    34      1        1\n",
       "Jude         0     0     0     2     0        0     3      2        0\n",
       "Luke         1    56     0   473    55       67    57      1        5\n",
       "Mark         1    21     0    75    52       61    11      0        0\n",
       "Matthew      2    25     0   102    70      130    26      1        3\n",
       "Paul         3    28     0    41     3       11   582      1        3\n",
       "Peter        0     3     1     3     0        2    28      4        1\n",
       "Unknown      0    14     0    15     0        6    44      1       22"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(metrics.confusion_matrix(y_test,predsvc), \n",
    "      index=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'], \n",
    "     columns=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'])\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       James       0.27      0.07      0.12        41\n",
      "        John       0.69      0.71      0.70       468\n",
      "        Jude       0.00      0.00      0.00         7\n",
      "        Luke       0.61      0.66      0.63       715\n",
      "        Mark       0.27      0.24      0.25       221\n",
      "     Matthew       0.42      0.36      0.39       359\n",
      "        Paul       0.72      0.87      0.79       672\n",
      "       Peter       0.33      0.10      0.15        42\n",
      "     Unknown       0.63      0.22      0.32       102\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      2627\n",
      "   macro avg       0.44      0.36      0.37      2627\n",
      "weighted avg       0.59      0.61      0.59      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6082984392843548\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.60784314, 0.57635468, 0.54228856, 0.55223881, 0.53768844,\n",
       "       0.58080808, 0.56122449, 0.55102041, 0.56122449, 0.57653061])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(text_clf_lsvc, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#run Naive Bayes first\n",
    "text_clf_lr.fit(X_train, y_train)\n",
    "\n",
    "#run predictions\n",
    "predlr = text_clf_lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>James</th>\n",
       "      <th>John</th>\n",
       "      <th>Jude</th>\n",
       "      <th>Luke</th>\n",
       "      <th>Mark</th>\n",
       "      <th>Matthew</th>\n",
       "      <th>Paul</th>\n",
       "      <th>Peter</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jude</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luke</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthew</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         James  John  Jude  Luke  Mark  Matthew  Paul  Peter  Unknown\n",
       "James        0     2     0     4     0        1    34      0        0\n",
       "John         0   295     0    95     5       16    56      0        1\n",
       "Jude         0     1     0     2     0        0     4      0        0\n",
       "Luke         0    39     0   540     7       30    99      0        0\n",
       "Mark         0    23     0   116    30       33    19      0        0\n",
       "Matthew      0    39     0   169    12       93    46      0        0\n",
       "Paul         0    24     0    54     0        2   590      0        2\n",
       "Peter        0     2     0     4     0        0    36      0        0\n",
       "Unknown      0    14     0    25     0        1    58      0        4"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame(metrics.confusion_matrix(y_test,predlr), \n",
    "      index=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'], \n",
    "     columns=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'])\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       James       0.00      0.00      0.00        41\n",
      "        John       0.67      0.63      0.65       468\n",
      "        Jude       0.00      0.00      0.00         7\n",
      "        Luke       0.54      0.76      0.63       715\n",
      "        Mark       0.56      0.14      0.22       221\n",
      "     Matthew       0.53      0.26      0.35       359\n",
      "        Paul       0.63      0.88      0.73       672\n",
      "       Peter       0.00      0.00      0.00        42\n",
      "     Unknown       0.57      0.04      0.07       102\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2627\n",
      "   macro avg       0.39      0.30      0.29      2627\n",
      "weighted avg       0.57      0.59      0.54      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5907879710696612\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.54901961, 0.54187192, 0.52736318, 0.55223881, 0.55778894,\n",
       "       0.57070707, 0.55102041, 0.54591837, 0.54591837, 0.55612245])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(text_clf_lr, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntdoc = nlp(''.join(asv[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the bags.\n",
    "ntwords = bag_of_words(ntdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n"
     ]
    }
   ],
   "source": [
    "# Create our data frame with features.\n",
    "word_counts = bow_features(df2, ntwords)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.25\n",
    "                                                    )\n",
    "\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Naive Bayes first\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#run predictions\n",
    "prednb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbownb = pd.DataFrame(metrics.confusion_matrix(y_test,prednb), \n",
    "      index=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'], \n",
    "     columns=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'])\n",
    "dfbownb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,prednb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test,prednb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(nb, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Naive Bayes first\n",
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "#run predictions\n",
    "predsvc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbowsvc = pd.DataFrame(metrics.confusion_matrix(y_test,predsvc), \n",
    "      index=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'], \n",
    "     columns=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'])\n",
    "dfbownsvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(svc, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Naive Bayes first\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#run predictions\n",
    "predlr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbowlr = pd.DataFrame(metrics.confusion_matrix(y_test,predlr), \n",
    "      index=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'], \n",
    "     columns=['James','John','Jude',\n",
    "            'Luke','Mark','Matthew','Paul',\n",
    "            'Peter','Unknown'])\n",
    "dfbowlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test,predlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
