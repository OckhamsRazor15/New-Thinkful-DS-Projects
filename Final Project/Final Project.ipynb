{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the goal of this project?\n",
    "\n",
    "#### The school world contains so much data and yet barely any schools are taking advantage of it.\n",
    "#### Their administrators don't have the time to dig deep into the data and pull out information\n",
    "#### This project will act almost as a POC to a potential plugin/dashboard that schools can enter into their Student Information Systems where administrators can quickly yield results that will help guide them to action\n",
    "\n",
    "#### Some questions that we will be exploring: Can we predict the ELA (English Language Acquisition) status/level of a student based on their grade? What about their current english grade based on the previous 2 years of English test grades? Taking a mixed effect model and looking at differences. \n",
    "#### There are many more questions we can ask of the data, but for our current scope, we will focus on these 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "import pylab \n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1478, 18)\n",
      "Index(['student_number', 'grade_level', 'ca_elastatus', 'Race', 'Zip', 'E1',\n",
      "       'E2', 'E3', 'M1', 'M2', 'M3', 'Days Attended', 'Days Absent 2018-2019',\n",
      "       'Days Enrolled 2018-2019', 'Attendance Rate 2018-2019',\n",
      "       'Absent Rate 2018-2019', 'Current English Grade', 'Current Math Grade'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Loading the data in long format (each respondent has one row per response)\n",
    "data2=pd.read_csv('Report.csv')\n",
    "#elaDummies = pd.get_dummies(data[\"ca_elastatus\"])\n",
    "#data = data.append(elaDummies)\n",
    "print(data2.shape)\n",
    "print(data2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleanup and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm not exactly happy with this as we're essentially giving students 0 for missing data, but we have to start somewhere\n",
    "#I might run another dataset dropping them and looking at the difference.\n",
    "data2= data2.fillna(0)\n",
    "#data= data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is going to take our grades that are in letters and convert them to numbers\n",
    "#We're not going to worry too much about the + and - even though they have a slight difference, we will group them\n",
    "def conditions(x):\n",
    "    if (x == 'A' or x == 'A-'):\n",
    "        return 1\n",
    "    elif (x == 'B' or x == 'B+' or x == 'B-'):\n",
    "        return 2\n",
    "    elif (x == 'C' or x == 'C+' or x == 'C-'):\n",
    "        return 3\n",
    "    elif (x == 'D' or x == 'D-' or x == 'D+'):\n",
    "        return 4\n",
    "    elif (x == 'F'):\n",
    "        return 5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "func = np.vectorize(conditions)\n",
    "#do it for english grades\n",
    "EngGradeDummies = func(data2[\"Current English Grade\"])\n",
    "data2[\"CurEngGrade\"] = EngGradeDummies\n",
    "\n",
    "#math\n",
    "MathGradeDummies = func(data2[\"Current Math Grade\"])\n",
    "data2[\"CurMathGrade\"] = MathGradeDummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will take our ELA status and convert them to numbers\n",
    "#dummy this now\n",
    "def conditionsEla(x):\n",
    "    if x == 'EO':\n",
    "        return 1\n",
    "    elif x == 'EL':\n",
    "        return 2\n",
    "    elif x == 'IFEP':\n",
    "        return 3\n",
    "    elif x == 'RFEP':\n",
    "        return 4\n",
    "    \n",
    "\n",
    "func = np.vectorize(conditionsEla)\n",
    "#elaDummies = func(data[\"ca_elastatus\"])\n",
    "elaDummies = pd.get_dummies(data2[\"ca_elastatus\"])\n",
    "data = pd.concat([data2, elaDummies], axis=1)\n",
    "#data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE for race\n",
    "race = pd.get_dummies(data2[\"Race\"])\n",
    "data = pd.concat([data,race], axis=1)\n",
    "#data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data[\"absentrate\"] = data[\"Days Absent 2018-2019\"]\n",
    "#create our X variable\n",
    "mainSet = data[[\"grade_level\", \"absentrate\", \"E1\", \"E2\", 'E3'\n",
    "         , \"M1\", \"M2\", \"M3\", \"Zip\", \"CurEngGrade\", \"CurMathGrade\", \"EO\", \"EL\", \"IFEP\", \"RFEP\", \"Black or African American\",\n",
    "           \"Cambodian\", \"Chinese\", \"Filipino\", \"Hispanic\", \"Multi\", \"Other Pac Islander\", \"White\", \"American Indian or Alaska Native\",\n",
    "             'Guamanian', 'Hmong','Vietnamese', 'Can', 'Laotian', 'Other Asian', 'Samoan' ]]\n",
    "\n",
    " \n",
    "#\"CurEngGrade\"\n",
    "X = mainSet[[\"grade_level\",\"E1\",\"E2\", \"E3\", \"absentrate\", \"EO\", \"EL\", \"IFEP\", \"RFEP\",\"Black or African American\",\n",
    "           \"Cambodian\", \"Chinese\", \"Filipino\", \"Hispanic\", \"Multi\", \"Other Pac Islander\", \"White\", \"American Indian or Alaska Native\",\n",
    "             'Guamanian', 'Hmong','Vietnamese', 'Can', 'Laotian', 'Other Asian', 'Samoan']]\n",
    "\n",
    "#clean up \n",
    "X[\"E1\"] = np.where(X[\"E1\"] == ' ', 0, X[\"E1\"]).astype(\"int\")\n",
    "\n",
    "X[\"E2\"] = np.where(X[\"E2\"] == ' ', 0, X[\"E2\"]).astype(\"int\")\n",
    "\n",
    "X[\"E3\"] = np.where(X[\"E3\"] == ' ', 0, X[\"E3\"]).astype(\"int\")\n",
    "\n",
    "#squared\n",
    "for x1 in X:\n",
    "    X[x1 +\"_Sq\"] = X[x1] ** 2\n",
    "\n",
    "#log\n",
    "def getlog(x):\n",
    "    if x > 0:\n",
    "        return math.log(x)\n",
    "    else:\n",
    "        return x\n",
    " \n",
    "for x2 in X:\n",
    "    X[x2 + \"_log\"] = X[x2].apply(getlog)\n",
    "\n",
    "#square root\n",
    "def squareroot(x):\n",
    "    if x > 1:\n",
    "        return math.sqrt(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "for x3 in X:\n",
    "    X[x3 + \"_sqrt\"] = X[x3].apply(squareroot)    \n",
    "\n",
    "\n",
    "X[\"inDanger\"] = np.where(mainSet[\"CurEngGrade\"] >= 4, 1, 0).astype('int')\n",
    "y = X[\"inDanger\"]\n",
    "X = X.drop(\"inDanger\", axis=1)\n",
    "\n",
    "#X = (X - X.mean()) / (X.max() - X.min())\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the spaces in some areas\n",
    "y = np.where(y == ' ', 0, y).astype(\"int\")\n",
    "\n",
    "#X[\"E1\"] = np.where(X[\"E1\"] == ' ', 0, X[\"E1\"]).astype(\"int\")\n",
    "\n",
    "#X[\"E2\"] = np.where(X[\"E2\"] == ' ', 0, X[\"E2\"]).astype(\"int\")\n",
    "\n",
    "#X[\"E3\"] = np.where(X[\"E3\"] == ' ', 0, X[\"E3\"]).astype(\"int\")\n",
    "\n",
    "#X[\"M1\"] = np.where(X[\"M1\"] == ' ', 0, X[\"M1\"]).astype(\"int\")\n",
    "\n",
    "#X[\"M2\"] = np.where(X[\"M2\"] == ' ', 0, X[\"M2\"]).astype(\"int\")\n",
    "\n",
    "#X[\"M3\"] = np.where(X[\"M3\"] == ' ', 0, X[\"M3\"]).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data for analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = PCA(33).fit_transform(X_train)\n",
    "X_test_pca = PCA(33).fit_transform(X_test)\n",
    "#y_train_pca = PCA(5).fit_transform(y_train)\n",
    "#y_test_pca = PCA(5).fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I like the 3 clusters\n",
    "y_pred = KMeans(n_clusters=4).fit_predict(pca)\n",
    "\n",
    "# Plot the solution.\n",
    "plt.scatter(pca[:, 0], pca[:, 1], c=y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Check the solution against the data.\n",
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at silhouette score\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Generating the sample data from make_blobs\n",
    "# This particular setting has one distinct cluster and 3 clusters placed close\n",
    "# together.\n",
    "X1 = pca\n",
    "\n",
    "y = y_pred\n",
    "\n",
    "\n",
    "# For reproducibility\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X1) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X1)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X1, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X1, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x1 in X:\n",
    "    sns.distplot(X[x1])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x1 in X:\n",
    "    sns.boxplot(x=y,y=X[x1] )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x1 in X:\n",
    "    print(x1)\n",
    "    stats.probplot(X[x1], dist=\"norm\", plot=pylab)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(15,15))\n",
    "#sns.heatmap(X.corr(), annot=True, ax=ax)\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a lot of categorical data\n",
    "#### Some of it is due to converting the grades and ELA status to OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The interesting one for me is our distribution of ELA status at the bottom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting E1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will start with a logistic regression as this is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients\n",
      "[[ 0.25986164 -0.04715959  0.27273201 -0.13517814  0.08424248 -0.00531525\n",
      "   0.09289651 -0.41273131 -0.06020832 -0.17542672 -0.13478198 -0.08054369\n",
      "  -0.1911518   0.01862661  0.20268241 -0.01532715  0.09361134 -0.12892799\n",
      "  -0.10154571 -0.00563063 -0.03957812 -0.04160786 -0.1684857  -0.06457529\n",
      "  -0.10969397 -0.03309377 -0.06512641 -0.17857709 -0.05344601 -0.00286214\n",
      "  -0.00531525  0.09289651 -0.41273131 -0.06020832 -0.17542672 -0.13478198\n",
      "  -0.08054369 -0.1911518   0.01862661  0.20268241 -0.01532715  0.09361134\n",
      "  -0.12892799 -0.10154571 -0.00563063 -0.03957812 -0.04160786 -0.1684857\n",
      "  -0.06457529 -0.10969397 -0.1833042   0.09514279 -0.0362376   0.0801555\n",
      "  -0.17616959  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.3666084   0.19028559 -0.07247521\n",
      "   0.160311   -0.35233918  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -0.35405775 -0.20743219\n",
      "   0.37103443 -0.20097094  0.29092234 -0.00531525  0.09289651 -0.41273131\n",
      "  -0.06020832 -0.17542672 -0.13478198 -0.08054369 -0.1911518   0.01862661\n",
      "   0.20268241 -0.01532715  0.09361134 -0.12892799 -0.10154571 -0.00563063\n",
      "  -0.03957812 -0.04160786 -0.1684857  -0.06457529 -0.10969397  0.25986164\n",
      "  -0.04715959  0.27273201 -0.13517814  0.08424248 -0.00531525  0.09289651\n",
      "  -0.41273131 -0.06020832 -0.17542672 -0.13478198 -0.08054369 -0.1911518\n",
      "   0.01862661  0.20268241 -0.01532715  0.09361134 -0.12892799 -0.10154571\n",
      "  -0.00563063 -0.03957812 -0.04160786 -0.1684857  -0.06457529 -0.10969397\n",
      "  -0.32577794  0.15835943 -0.04321388  0.09089133  0.25791155  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.46071958 -0.14493355  0.06402629  0.10827297  0.24832455\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]]\n",
      "\n",
      " Accuracy by E1\n",
      "col_0    0   1\n",
      "row_0         \n",
      "0      338  32\n",
      "\n",
      " Percentage accuracy\n",
      "0.9052346570397112\n",
      "Cross Val Score\n",
      "[0.89473684 0.94736842 0.89189189 0.91891892 0.91891892 0.91891892\n",
      " 0.91891892 0.89189189 0.91666667 0.91666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sakok\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Declare a logistic regression classifier.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "\n",
    "#lr = ensemble.GradientBoostingClassifier(subsample=.2, n_estimators=300, max_features=2)\n",
    "lr = LogisticRegression()\n",
    "# Fit the model.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Display.\n",
    "print('Coefficients')\n",
    "print(lr.coef_)\n",
    "\n",
    "#print(lr.intercept_)\n",
    "pred_y = lr.predict(X_test)\n",
    "\n",
    "print('\\n Accuracy by E1')\n",
    "print(pd.crosstab(pred_y, y_test))\n",
    "\n",
    "print('\\n Percentage accuracy')\n",
    "print(lr.score(X_train, y_train))\n",
    "\n",
    "print(\"Cross Val Score\")\n",
    "print(cross_val_score(lr,X_test,y_test,cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, pred_rfc)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "   rf = ensemble.RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "   rf = ensemble.RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, \"b\", label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_results, \"r\", label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "   rf = ensemble.RandomForestClassifier(min_samples_split=min_samples_split)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_splits, train_results, \"b\", label=\"Train AUC\")\n",
    "line2, = plt.plot(min_samples_splits, test_results, \"r\", label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.xlabel('min samples split')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "   rf = ensemble.RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(min_samples_leafs, train_results, \"b\", label=\"Train AUC\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, \"r\", label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('min samples leaf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = list(range(1,train.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "   rf = ensemble.RandomForestClassifier(max_features=max_feature)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(x_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_features, train_results, ‘b’, label=”Train AUC”)\n",
    "line2, = plt.plot(max_features, test_results, ‘r’, label=”Test AUC”)\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(‘AUC score’)\n",
    "plt.xlabel(‘max features’)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we will look at a random forest\n",
    "from sklearn import ensemble\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier( n_estimators=250, max_depth=5, max_features=30, min_samples_split=.1)\n",
    "\n",
    "rfc.fit(X_train,y_train)\n",
    "pred_rfc = rfc.predict(X_test) \n",
    "\n",
    "print(rfc.score(X_train,y_train))\n",
    "print('\\n Accuracy by ela status')\n",
    "print(pd.crosstab(pred_rfc, y_test))\n",
    "\n",
    "cross_val_score(rfc,X_test, y_test,cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(C=.5)\n",
    "svc.fit(X_train, y_train)\n",
    "#predictions\n",
    "predsvc = svc.predict(X_test)\n",
    "\n",
    "print(svc.score(X_train,y_train))\n",
    "print('\\n Accuracy by ela status')\n",
    "print(pd.crosstab(predsvc, y_test))\n",
    "\n",
    "cross_val_score(svc,X_test, y_test,cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
